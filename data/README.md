# Data Directory

This directory contains all datasets used for training and evaluation of NeuroVoice.

## Directory Structure

```
data/
├── daic_woz/              # DAIC-WOZ depression dataset
├── parkinson_tsi/         # Parkinson's Telemonitoring Dataset (UCI)
├── dementiabank/          # DementiaBank Pitt Corpus (Alzheimer's)
└── faces/                 # Facial expression datasets (FER2013)
```

## Dataset Details

### 1. DAIC-WOZ (Depression)

**Location**: `data/daic_woz/`

**Source**: [https://dcapswoz.ict.usc.edu/](https://dcapswoz.ict.usc.edu/)

**Contents**:
- Audio files (.wav)
- Video files (.mp4)
- Transcripts (.csv)
- Metadata (PHQ-8 scores, labels)

**Download Instructions**:
1. Register at the DAIC-WOZ website
2. Accept the terms of use
3. Download the dataset manually or use `scripts/download_data.py` with credentials

### 2. Parkinson's Telemonitoring Dataset

**Location**: `data/parkinson_tsi/`

**Source**: [https://archive.ics.uci.edu/ml/datasets/parkinsons](https://archive.ics.uci.edu/ml/datasets/parkinsons)

**Contents**:
- Voice recordings (.wav)
- Feature files (.csv)
- Labels (parkinson/normal)

**Download Instructions**:
Run: `python scripts/download_data.py --dataset parkinson`

### 3. DementiaBank Pitt Corpus (Alzheimer's)

**Location**: `data/dementiabank/`

**Source**: [https://dementia.talkbank.org/access/English/Pitt.html](https://dementia.talkbank.org/access/English/Pitt.html)

**Contents**:
- Speech recordings (.wav)
- Transcripts (.cha files)
- Demographics and clinical labels

**Download Instructions**:
1. Register at DementiaBank
2. Agree to terms of use
3. Download manually or use `scripts/download_data.py` with credentials

### 4. FER2013 (Facial Expressions)

**Location**: `data/faces/fer2013/`

**Source**: [https://www.kaggle.com/datasets/msambare/fer2013](https://www.kaggle.com/datasets/msambare/fer2013)

**Contents**:
- Facial expression images (48x48 grayscale)
- 7 emotion classes: Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral

**Download Instructions**:
Requires Kaggle API setup:
```bash
pip install kaggle
# Configure kaggle credentials (see Kaggle API documentation)
python scripts/download_data.py --dataset fer2013
```

## Preprocessed Data

After running preprocessing scripts, you'll find processed data in:

- `data/processed/audio/` - Extracted audio features (MFCC, wav2vec embeddings)
- `data/processed/video/` - Facial landmarks and emotion embeddings
- `data/processed/multimodal/` - Fused features ready for training

## Data Splits

Train/validation/test splits are stored in:

- `data/splits/train.csv`
- `data/splits/val.csv`
- `data/splits/test.csv`

Generated by running: `python scripts/split_data.py`

## Notes

- **Data Privacy**: All datasets used are publicly available for research purposes
- **Ethics**: Ensure compliance with dataset terms of use
- **Storage**: Large audio/video files are excluded from git (see .gitignore)
- **Placeholders**: Empty `.gitkeep` files maintain directory structure in git

## File Naming Conventions

- Audio: `{dataset}_{patient_id}_{session}_{segment}.wav`
- Video: `{dataset}_{patient_id}_{session}.mp4`
- Features: `{dataset}_{patient_id}_{feature_type}.npy`
- Labels: `labels_{disease}.csv`

